{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db3d9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå ERROR: File not found at data/raw/train.csv\n",
      "Current directory: c:\\Projects\\credit-risk-model\\notebooks\n",
      "\n",
      "Files in data/raw/:\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'data/raw'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCurrent directory:\u001b[39m\u001b[33m\"\u001b[39m, os.getcwd())\n\u001b[32m     42\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFiles in data/raw/:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata/raw\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[32m     44\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# Create empty dataframes to prevent further errors\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] The system cannot find the path specified: 'data/raw'"
     ]
    }
   ],
   "source": [
    "# Cell 1 - UPDATED FOR YOUR SPECIFIC PATH\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "# Your specific path - train.csv is now in data/raw/\n",
    "train_path = 'data/raw/train.csv'\n",
    "\n",
    "# Check if file exists\n",
    "if os.path.exists(train_path):\n",
    "    # Load the data\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    \n",
    "    print(\"‚úÖ Data loaded successfully!\")\n",
    "    print(f\"File: {train_path}\")\n",
    "    print(f\"Size: {os.path.getsize(train_path)/1024/1024:.2f} MB\")\n",
    "    print(f\"Shape: {train_df.shape}\")\n",
    "    print(f\"Columns: {list(train_df.columns)}\")\n",
    "    \n",
    "    # Check if we have a test file\n",
    "    test_path = 'data/raw/test.csv'\n",
    "    if os.path.exists(test_path):\n",
    "        test_df = pd.read_csv(test_path)\n",
    "        print(f\"\\n‚úÖ Test data loaded: {test_df.shape}\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è No test.csv found, using train as reference\")\n",
    "        test_df = train_df.copy()\n",
    "        \n",
    "else:\n",
    "    print(f\"‚ùå ERROR: File not found at {train_path}\")\n",
    "    print(\"Current directory:\", os.getcwd())\n",
    "    print(\"\\nFiles in data/raw/:\")\n",
    "    for f in os.listdir('data/raw'):\n",
    "        print(f\"  - {f}\")\n",
    "    \n",
    "    # Create empty dataframes to prevent further errors\n",
    "    train_df = pd.DataFrame()\n",
    "    test_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf55cc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"BASIC DATA OVERVIEW\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Display first few rows\n",
    "train_df.head()\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nüìä DATA TYPES:\")\n",
    "print(train_df.dtypes)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nüîç MISSING VALUES:\")\n",
    "missing = train_df.isnull().sum()\n",
    "if missing.sum() > 0:\n",
    "    print(missing[missing > 0])\n",
    "else:\n",
    "    print(\"‚úÖ No missing values found!\")\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nüìà BASIC STATISTICS:\")\n",
    "print(train_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fac06eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots for visualizations\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle('Key Feature Distributions', fontsize=16)\n",
    "\n",
    "# 1. Transaction Amount Distribution\n",
    "axes[0, 0].hist(train_df['Amount'].dropna(), bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_title('Transaction Amount Distribution')\n",
    "axes[0, 0].set_xlabel('Amount')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# 2. Fraud Distribution\n",
    "fraud_counts = train_df['FraudResult'].value_counts()\n",
    "axes[0, 1].bar(fraud_counts.index, fraud_counts.values, color=['green', 'red'])\n",
    "axes[0, 1].set_title('Fraud Distribution (0=No, 1=Yes)')\n",
    "axes[0, 1].set_xlabel('Fraud Result')\n",
    "axes[0, 1].set_ylabel('Count')\n",
    "for i, v in enumerate(fraud_counts.values):\n",
    "    axes[0, 1].text(i, v, str(v), ha='center', va='bottom')\n",
    "\n",
    "# 3. Product Category Distribution\n",
    "top_categories = train_df['ProductCategory'].value_counts().head(10)\n",
    "axes[0, 2].barh(range(len(top_categories)), top_categories.values)\n",
    "axes[0, 2].set_yticks(range(len(top_categories)))\n",
    "axes[0, 2].set_yticklabels(top_categories.index)\n",
    "axes[0, 2].set_title('Top 10 Product Categories')\n",
    "axes[0, 2].set_xlabel('Count')\n",
    "\n",
    "# 4. Channel Distribution\n",
    "channel_counts = train_df['ChannelId'].value_counts()\n",
    "axes[1, 0].pie(channel_counts.values, labels=channel_counts.index, autopct='%1.1f%%')\n",
    "axes[1, 0].set_title('Transaction Channels')\n",
    "\n",
    "# 5. Transaction Hour Distribution\n",
    "train_df['hour'] = pd.to_datetime(train_df['TransactionStartTime']).dt.hour\n",
    "hour_counts = train_df['hour'].value_counts().sort_index()\n",
    "axes[1, 1].plot(hour_counts.index, hour_counts.values, marker='o')\n",
    "axes[1, 1].set_title('Transactions by Hour of Day')\n",
    "axes[1, 1].set_xlabel('Hour (0-23)')\n",
    "axes[1, 1].set_ylabel('Transaction Count')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Country Code Distribution\n",
    "country_counts = train_df['CountryCode'].value_counts().head(10)\n",
    "axes[1, 2].bar(range(len(country_counts)), country_counts.values)\n",
    "axes[1, 2].set_xticks(range(len(country_counts)))\n",
    "axes[1, 2].set_xticklabels(country_counts.index, rotation=45)\n",
    "axes[1, 2].set_title('Top 10 Country Codes')\n",
    "axes[1, 2].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b903b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"CUSTOMER-LEVEL ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calculate basic customer metrics\n",
    "customer_stats = train_df.groupby('CustomerId').agg({\n",
    "    'TransactionId': 'count',\n",
    "    'Amount': ['sum', 'mean', 'std'],\n",
    "    'FraudResult': 'sum'\n",
    "})\n",
    "\n",
    "customer_stats.columns = ['transaction_count', 'total_amount', 'avg_amount', 'std_amount', 'fraud_count']\n",
    "customer_stats = customer_stats.reset_index()\n",
    "\n",
    "print(f\"üìä Unique customers: {customer_stats.shape[0]:,}\")\n",
    "print(f\"üìä Average transactions per customer: {customer_stats['transaction_count'].mean():.2f}\")\n",
    "print(f\"üìä Customers with fraud: {(customer_stats['fraud_count'] > 0).sum():,}\")\n",
    "print(f\"üìä Fraud rate among customers: {(customer_stats['fraud_count'] > 0).mean()*100:.2f}%\")\n",
    "\n",
    "# Display customer statistics\n",
    "print(\"\\nüìà Customer Statistics Summary:\")\n",
    "print(customer_stats.describe())\n",
    "\n",
    "# Plot customer transaction distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Transaction count distribution\n",
    "axes[0].hist(customer_stats['transaction_count'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('Transactions per Customer')\n",
    "axes[0].set_xlabel('Number of Transactions')\n",
    "axes[0].set_ylabel('Number of Customers')\n",
    "\n",
    "# Total amount distribution\n",
    "axes[1].hist(customer_stats['total_amount'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1].set_title('Total Amount per Customer')\n",
    "axes[1].set_xlabel('Total Amount')\n",
    "axes[1].set_ylabel('Number of Customers')\n",
    "\n",
    "# Average amount distribution\n",
    "axes[2].hist(customer_stats['avg_amount'].dropna(), bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[2].set_title('Average Transaction Amount per Customer')\n",
    "axes[2].set_xlabel('Average Amount')\n",
    "axes[2].set_ylabel('Number of Customers')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7c9a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"TIME-BASED ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Convert to datetime\n",
    "train_df['TransactionStartTime'] = pd.to_datetime(train_df['TransactionStartTime'])\n",
    "\n",
    "# Extract time features\n",
    "train_df['date'] = train_df['TransactionStartTime'].dt.date\n",
    "train_df['day_of_week'] = train_df['TransactionStartTime'].dt.day_name()\n",
    "train_df['month'] = train_df['TransactionStartTime'].dt.month\n",
    "train_df['hour'] = train_df['TransactionStartTime'].dt.hour\n",
    "\n",
    "# Daily transaction trends\n",
    "daily_transactions = train_df.groupby('date').agg({\n",
    "    'TransactionId': 'count',\n",
    "    'Amount': 'sum',\n",
    "    'FraudResult': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "daily_transactions.columns = ['date', 'transaction_count', 'total_amount', 'fraud_count']\n",
    "\n",
    "print(\"üìÖ Daily Transaction Trends:\")\n",
    "print(f\"Date range: {daily_transactions['date'].min()} to {daily_transactions['date'].max()}\")\n",
    "print(f\"Total days: {daily_transactions.shape[0]}\")\n",
    "\n",
    "# Plot daily trends\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Daily transaction count\n",
    "axes[0, 0].plot(daily_transactions['date'], daily_transactions['transaction_count'])\n",
    "axes[0, 0].set_title('Daily Transaction Count')\n",
    "axes[0, 0].set_xlabel('Date')\n",
    "axes[0, 0].set_ylabel('Transactions')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Daily total amount\n",
    "axes[0, 1].plot(daily_transactions['date'], daily_transactions['total_amount'])\n",
    "axes[0, 1].set_title('Daily Total Amount')\n",
    "axes[0, 1].set_xlabel('Date')\n",
    "axes[0, 1].set_ylabel('Total Amount')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Day of week analysis\n",
    "dow_counts = train_df['day_of_week'].value_counts()\n",
    "dow_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "dow_counts = dow_counts.reindex(dow_order)\n",
    "axes[1, 0].bar(dow_counts.index, dow_counts.values)\n",
    "axes[1, 0].set_title('Transactions by Day of Week')\n",
    "axes[1, 0].set_xlabel('Day of Week')\n",
    "axes[1, 0].set_ylabel('Transaction Count')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Hour of day analysis (already calculated)\n",
    "hour_counts = train_df['hour'].value_counts().sort_index()\n",
    "axes[1, 1].bar(hour_counts.index, hour_counts.values)\n",
    "axes[1, 1].set_title('Transactions by Hour of Day')\n",
    "axes[1, 1].set_xlabel('Hour (0-23)')\n",
    "axes[1, 1].set_ylabel('Transaction Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c04275",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Select numerical columns for correlation\n",
    "numerical_cols = ['Amount', 'Value', 'FraudResult', 'hour']\n",
    "corr_data = train_df[numerical_cols].copy()\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = corr_data.corr()\n",
    "\n",
    "print(\"üìä Correlation Matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Visualize correlation matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Check correlation with FraudResult\n",
    "print(\"\\nüîç Correlation with FraudResult:\")\n",
    "fraud_corr = correlation_matrix['FraudResult'].sort_values(ascending=False)\n",
    "for feature, corr_value in fraud_corr.items():\n",
    "    if feature != 'FraudResult':\n",
    "        print(f\"{feature}: {corr_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a89814",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"OUTLIER DETECTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create box plots for numerical features\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Amount box plot\n",
    "axes[0].boxplot(train_df['Amount'].dropna())\n",
    "axes[0].set_title('Transaction Amount Box Plot')\n",
    "axes[0].set_ylabel('Amount')\n",
    "\n",
    "# Value box plot\n",
    "axes[1].boxplot(train_df['Value'].dropna())\n",
    "axes[1].set_title('Transaction Value Box Plot')\n",
    "axes[1].set_ylabel('Value')\n",
    "\n",
    "# Transaction count per customer box plot\n",
    "axes[2].boxplot(customer_stats['transaction_count'])\n",
    "axes[2].set_title('Transactions per Customer Box Plot')\n",
    "axes[2].set_ylabel('Transaction Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate outliers using IQR method\n",
    "def detect_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "print(\"\\nüìä Outlier Analysis for Amount:\")\n",
    "amount_outliers, lower_amt, upper_amt = detect_outliers_iqr(train_df, 'Amount')\n",
    "print(f\"Lower bound: {lower_amt:.2f}, Upper bound: {upper_amt:.2f}\")\n",
    "print(f\"Number of outliers: {len(amount_outliers):,} ({len(amount_outliers)/len(train_df)*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nüìä Outlier Analysis for Customer Transaction Count:\")\n",
    "count_outliers, lower_cnt, upper_cnt = detect_outliers_iqr(customer_stats, 'transaction_count')\n",
    "print(f\"Lower bound: {lower_cnt:.2f}, Upper bound: {upper_cnt:.2f}\")\n",
    "print(f\"Number of outlier customers: {len(count_outliers):,} ({len(count_outliers)/len(customer_stats)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d1a3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"SUMMARY OF KEY INSIGHTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Compile key insights\n",
    "insights = []\n",
    "\n",
    "# Insight 1: Data Size\n",
    "insights.append(f\"1. Dataset contains {train_df.shape[0]:,} transactions for {customer_stats.shape[0]:,} unique customers.\")\n",
    "\n",
    "# Insight 2: Fraud Rate\n",
    "fraud_rate = train_df['FraudResult'].mean() * 100\n",
    "insights.append(f\"2. Overall fraud rate is {fraud_rate:.4f}% ({train_df['FraudResult'].sum():,} fraudulent transactions).\")\n",
    "\n",
    "# Insight 3: Customer Behavior\n",
    "avg_transactions = customer_stats['transaction_count'].mean()\n",
    "insights.append(f\"3. Average customer has {avg_transactions:.1f} transactions (range: {customer_stats['transaction_count'].min()} to {customer_stats['transaction_count'].max()}).\")\n",
    "\n",
    "# Insight 4: Time Patterns\n",
    "busiest_hour = train_df['hour'].value_counts().idxmax()\n",
    "insights.append(f\"4. Peak transaction hour: {busiest_hour}:00 with {train_df['hour'].value_counts().max():,} transactions.\")\n",
    "\n",
    "# Insight 5: Monetary Patterns\n",
    "top_category = train_df['ProductCategory'].value_counts().index[0]\n",
    "top_category_pct = train_df['ProductCategory'].value_counts().iloc[0] / len(train_df) * 100\n",
    "insights.append(f\"5. Most popular product category: '{top_category}' ({top_category_pct:.1f}% of transactions).\")\n",
    "\n",
    "# Print insights\n",
    "print(\"üîç TOP 5 INSIGHTS FOR FEATURE ENGINEERING:\")\n",
    "for i, insight in enumerate(insights, 1):\n",
    "    print(f\"{insight}\")\n",
    "\n",
    "# Save insights to file\n",
    "with open('../notebooks/eda_insights.txt', 'w') as f:\n",
    "    f.write(\"EDA KEY INSIGHTS\\n\")\n",
    "    f.write(\"================\\n\\n\")\n",
    "    for insight in insights:\n",
    "        f.write(f\"{insight}\\n\")\n",
    "    f.write(f\"\\nGenerated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "print(f\"\\nüíæ Insights saved to: notebooks/eda_insights.txt\")\n",
    "\n",
    "# Display sample of processed data\n",
    "print(\"\\nüìã SAMPLE OF ENRICHED DATA:\")\n",
    "sample_cols = ['CustomerId', 'TransactionStartTime', 'Amount', 'ProductCategory', 'ChannelId', 'hour', 'day_of_week']\n",
    "print(train_df[sample_cols].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da548c38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "credit-risk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
